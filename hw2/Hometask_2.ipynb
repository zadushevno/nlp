{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# О том, как собирался корпус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При создании корпуса я подбирала предложения из НКРЯ и интернета, в которых есть грамматическая омонимия: совпадение форм существительного и глагола (*ели*, *печь*), причастия и прилагательного (*следующий*), наречия и прилагательного, наречия и производного предлога (*навстречу*), предлога и деепричастия (*благодаря*), числительного и глагола (*три*), существительного и прилагательного (*жаркое*) и т.д. Кроме того, я добавила имена собственные, которые могут быть похожи на существительное или прилагательное (на -ов, -их. Чтобы правильно разметить часть речи в подобных сложных случаях, парсер должен ориентироваться на контекст и синтаксическую структуру предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для разметки я использовала немного измененный набор тэгов Universal Dependencies, поскольку он наиболее распространенный и отличается умеренной детализацией тэгов: все предлоги я обозначала одним тэгом CONJ, отказалась от тэга AUX, однако причастия и деепричастия обозначала тэгами PRTF и GRND соответственно, как это сделано в OpenCorpora, так как мне было необходимо понять, сможет ли парсер отличить эти части речи от, например, прилагательных. Полный тэгсет выглядит так:  \n",
    "\n",
    "VERB - глагол  \n",
    "NOUN - существительное  \n",
    "ADJ - прилагательное  \n",
    "PRTF - причастие  \n",
    "GRND - деепричастие  \n",
    "PRON - местоимение  \n",
    "DET - притяжательное местоимение  \n",
    "NUM - числительное  \n",
    "PART - частица  \n",
    "INTJ - междометие  \n",
    "CONJ - союз  \n",
    "ADP - предлог  \n",
    "ADV - наречие  \n",
    "PROPN - имя собственное "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тэггинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Я использовала для сравнения pymorphy2, natasha и spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: natasha in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: razdel>=0.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: ipymarkup>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.9.0)\n",
      "Requirement already satisfied: yargy>=0.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.15.0)\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.9.1)\n",
      "Requirement already satisfied: slovnet>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.5.0)\n",
      "Requirement already satisfied: navec>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from natasha) (0.10.0)\n",
      "Requirement already satisfied: intervaltree>=3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ipymarkup>=0.8.0->natasha) (3.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from navec>=0.9.0->natasha) (1.22.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (2.4.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (8.1.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (3.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.22.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (1.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ru-core-news-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.4.0/ru_core_news_sm-3.4.0-py3-none-any.whl (15.3 MB)\n",
      "     ---------------------------------------- 15.3/15.3 MB 8.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pymorphy2>=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.4.0) (0.9.1)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ru-core-news-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pymorphy2>=0.9->ru-core-news-sm==3.4.0) (2.4.417127.4579844)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.62.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (58.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.22.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->ru-core-news-sm==3.4.0) (2.0.1)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('ru_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pymorphy2\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, Doc, MorphVocab\n",
    "\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прогоняем корпус через тэггеры, сохраняем результат в виде списка кортежей. Для spacy и natasha я также сохраняла грамемму, обозначающую форму глагола, чтобы потом при приведении разметки к универсальным тэгам можно было глаголы заменить на деепричастия и причастия. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Наш основной разыгрывающий Вадим Хамуцких повредил палец и отправился на скамейку запасных.\n",
    "Штирлиц шел по лесу и увидел голубые ели.\n",
    "Что кинул он в краю родном?\n",
    "Что ж, это классика, господа! И сколько бы режиссеры сериалов не пытались «переплюнуть» Рязанова, у них это не получится.\n",
    "― Что ты всё думаешь о себе? ― спрашивает жена.\n",
    "Между блюдом майонеза и жарким ставятся по две кучки тарелок для жаркого.\n",
    "В Эстонии ― эстонский для русских, русский для эстонцев.\n",
    "Всемогущий Горшков обещал «устроить» ее на прямой поезд, следующий через станцию Семеновка, а там и до поселка рукой подать: всего двадцать пять километров.\n",
    "А прыгать туда нельзя, ща поезд следующий проедет, вон расписание.\n",
    "Поздно вечером подруги собирались у невесты для завивки ей волос, чтобы подготовить причёску к венцу\n",
    "Буду сидеть, курить, наслаждаться весенним утром, свежим воздухом и молодою пахучею зеленью недавно распустившихся деревьев\n",
    "Жарко в небе солнце летнее.\n",
    "Я плакала и жарко молилась.\n",
    "А я иду к тебе навстречу, и я несу тебе цветы.\n",
    "Все полевые цветы тянутся навстречу солнцу.\n",
    "Она помолилась и теперь, бла­годаря Бога за избавление, вернулась к себе.\n",
    "Благодаря отцу я и сестры знаем французский, немецкий и английский языки.\n",
    "Три дня не переставая шел дождь.\n",
    "Хорошенько три паркет щеткой!\n",
    "Пила раза два выпрыгнула, меняя место, словно ей было неулёжно, потом въелась и пошла.\n",
    "Год назад я не пила кофе после обеда.\n",
    "Печь нужна, чтобы печь в ней пирожки.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_spacy = nlp(corpus)\n",
    "spacy_pos = []\n",
    "for token in doc_spacy:\n",
    "  spacy_pos.append((token, token.pos_, token.morph.get('VerbForm')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_pos = []\n",
    "for word in nltk.word_tokenize(corpus):\n",
    "  pymorphy_pos.append((word, morph.parse(word)[0].tag.POS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "natasha_pos = []\n",
    "doc_natasha = Doc(corpus)\n",
    "doc_natasha.segment(segmenter)\n",
    "doc_natasha.tag_morph(morph_tagger)\n",
    "for token in doc_natasha.tokens:\n",
    "  natasha_pos.append((token.text, token.pos, token.feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция приводит тэгсет spacy и natasha к формату ручной разметки: в случае, если парсер разметил часть речи как глагол, смотрим на граммему 'VerbForm'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ud_tags_conventer(pair, parser):\n",
    "    word = pair[0]\n",
    "    tag = pair[1]\n",
    "    dict = {\"AUX\": \"VERB\", \"SCONJ\": \"CONJ\", \"CCONJ\": \"CONJ\", 'Conv' : 'GRND', 'Part' : 'PRTF', 'Fin' : 'VERB', 'Inf' : 'VERB'}\n",
    "    form = \"\"\n",
    "    if tag in dict.keys():\n",
    "        new_tag = dict[tag]\n",
    "    else:\n",
    "        if tag == 'VERB':\n",
    "            if parser == 'natasha':\n",
    "                form = pair[2]['VerbForm']\n",
    "                new_tag = dict[form]\n",
    "            if parser == 'spacy':\n",
    "                form = pair[2][0]\n",
    "                new_tag = dict[form]\n",
    "        else:\n",
    "            new_tag = tag\n",
    "    return((word, new_tag))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция приводит тэгсет pymorphy2 к формату ручной разметки: здесь важно было все притяжательные местоимения заменить на DET, так как они размечались как краткие прилагательные (для этого смотрим, есть ли тэг Apro в разметке)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymorphy_converter(pair):\n",
    "    word = pair[0]\n",
    "    tag = pair[1]\n",
    "    tags = {\n",
    "        \"ADJF\": \"ADJ\",\n",
    "        \"ADJS\": \"ADJ\",\n",
    "        \"COMP\": \"ADJ\",\n",
    "        \"INFN\": \"VERB\",\n",
    "        \"NUMR\": \"NUM\",\n",
    "        \"ADVB\": \"ADV\",\n",
    "        \"NPRO\": \"PRON\",\n",
    "        \"PRED\": \"ADV\",\n",
    "        \"PREP\": \"ADP\",\n",
    "        \"PRCL\": \"PART\",\n",
    "        \"PRTS\": \"PRTF\", \n",
    "        None : \"PUNCT\"\n",
    "    }\n",
    "    if 'Apro' in morph.parse(word)[0].tag:\n",
    "        new_tag = 'DET'\n",
    "    else:\n",
    "        if tag in tags.keys():\n",
    "            new_tag = tags[tag]\n",
    "        else:\n",
    "            new_tag = tag\n",
    "    return((word, new_tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приводим к единому формату:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymorphy_pos_norm = []\n",
    "natasha_pos_norm = []\n",
    "spacy_pos_norm = []\n",
    "for el in pymorphy_pos:\n",
    "    pymorphy_pos_norm.append(pymorphy_converter(el))\n",
    "for el in spacy_pos:\n",
    "    if not el[1] == 'SPACE':\n",
    "        spacy_pos_norm.append(ud_tags_conventer(el, 'spacy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for el in natasha_pos:\n",
    "    natasha_pos_norm.append(ud_tags_conventer(el, 'natasha'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_natasha = pd.DataFrame(natasha_pos_norm, columns=['Word', 'POS'])\n",
    "df_spacy = pd.DataFrame(spacy_pos_norm, columns=['Word', 'POS'])\n",
    "df_pymorphy = pd.DataFrame(pymorphy_pos_norm, columns=['Word', 'POS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.read_csv(\"corpus_pos.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаем accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(parser_df, base):\n",
    "    parser_tags = list(parser_df['POS'])\n",
    "    base_tags = list(base['POS'])\n",
    "    print(\"Accuracy: %.4f\" % accuracy_score(parser_tags, base_tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8869\n"
     ]
    }
   ],
   "source": [
    "count_accuracy(df_pymorphy, base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "count_accuracy(df_natasha, base_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8978\n"
     ]
    }
   ],
   "source": [
    "count_accuracy(df_spacy, base_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшим тэггером для русского оказался spacy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В предыдущем домашнем задании я работала с текстами на английском, но для этой домашки в первой части не решилась составлять корпус на английском, поскольку я не носитель, не знаю тонкостей английской морфологии и не смогла бы верно разметить части речи. Тем не менее, во второй части для написания чанкера буду использовать spacy - предполагаю, что для английского он бы тоже показал лучший результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем chunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Буду выделять следующие группы: \n",
    "- not + ADJ -- это позволит \"поймать\" случаи типа not good, когда отрицание меняет тональность на противоположную\n",
    "- ADV + ADJ -- такие сочетания ярче передают эмоциональную окраску, так как наречие усиливает значение прилагательного\n",
    "- not + VERB -- это случаи типа (did) not like, которые тоже влияют на тональность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.4.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 12.8/12.8 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (58.1.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.22.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.62.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.12)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.3; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('english')\n",
    "stops.remove('not')\n",
    "nlp_eng = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "изменим функцию lemmatize: вместо nltk будем использовать spacy, а еще добавим параметр 'pos', чтобы можно было в результате препроцессинга получить пары лемма - часть речи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x, pos = True, returnList = True):\n",
    "    if type(x) != str:\n",
    "        return \"\"\n",
    "    tokens = nlp_eng(x.lower())\n",
    "    result = []\n",
    "    for word in tokens:\n",
    "        if word.text.isalpha():\n",
    "            nf = word.lemma_\n",
    "            w_pos = word.pos_\n",
    "            if nf not in stops:\n",
    "                if pos == True:\n",
    "                    result.append((nf, w_pos))\n",
    "                else:\n",
    "                    result.append(nf)\n",
    "    if returnList == True:\n",
    "        return(result)\n",
    "    else:\n",
    "        return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(tokens):\n",
    "    bigrams = nltk.bigrams(tokens)\n",
    "    res = []\n",
    "    for el in bigrams:\n",
    "        first = el[0]\n",
    "        second = el[1]\n",
    "        if first[1] == 'ADV' and second[1] == 'ADJ':\n",
    "            res.append(first[0] + ' ' + second[0])\n",
    "        if first[0] == 'not' and second[1] == 'ADJ':\n",
    "            res.append(first[0] + ' ' + second[0])\n",
    "        if first[0] == 'not' and second[1] == 'VERB':\n",
    "            res.append(first[0] + ' ' + second[0])\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "код из предыдущей домашки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(url):\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albums(url): #функция, которая определяет список альбомов исполнителя\n",
    "    albums = []\n",
    "    page = parse_page(url)\n",
    "    r = page.find_all('td', {'class' : 'title brief_metascore'})\n",
    "    for album in r:\n",
    "        l = album.find('a').attrs['href']\n",
    "        albums.append(f'https://www.metacritic.com{l}/user-reviews')\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_albums = get_albums('https://www.metacritic.com/person/kanye-west')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reviews(url): #функция, которая парсит рецензии, на вход подается ссылка на страницу с альбомом\n",
    "    all_reviews = []\n",
    "    page = parse_page(url)\n",
    "    reviews = page.find_all('div', {'class' : 'review_content'})\n",
    "    for review in reviews:\n",
    "        dic = {}\n",
    "        dic['text'] = review.find_all('div', {'class' : 'review_body'})[0].text.strip()\n",
    "        dic['grade'] = review.find_all('div', {'class' : 'review_grade'})[0].text.strip()\n",
    "        all_reviews.append(dic)\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for album in k_albums:\n",
    "    reviews.extend(parse_reviews(album))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(reviews) #превращаем данные в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_to_sentiment(x): #выделяем положительные и отрицательные отзывы\n",
    "    if x > 10: #некоторые оценки на сайте по 100-балльной шкале\n",
    "        sent = x / 10\n",
    "    else:\n",
    "        sent = x\n",
    "    if sent <= 5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immensely mediocre. I hope Ye doesn't make any...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very poor album with poor production and a lot...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's clearly unfinished. The best is yet to co...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This review contains spoilers, click expand to...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donda, Donda, DondaDonda, Donda, Donda, Donda,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Now I usually like the rock music. Actually no...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>This album was the BOMB!</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Like every hip-hop album (even the great ones)...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Most producers who approach the mic do so at t...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Delivers both ass-shakers and contemplative cuts.</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  grade  sentiment\n",
       "0     Immensely mediocre. I hope Ye doesn't make any...    3.0          0\n",
       "1     very poor album with poor production and a lot...    3.0          0\n",
       "2     It's clearly unfinished. The best is yet to co...    7.0          1\n",
       "3     This review contains spoilers, click expand to...    7.0          1\n",
       "4     Donda, Donda, DondaDonda, Donda, Donda, Donda,...   10.0          1\n",
       "...                                                 ...    ...        ...\n",
       "1183  Now I usually like the rock music. Actually no...    9.0          1\n",
       "1184                           This album was the BOMB!   10.0          1\n",
       "1185  Like every hip-hop album (even the great ones)...   70.0          1\n",
       "1186  Most producers who approach the mic do so at t...   70.0          1\n",
       "1187  Delivers both ass-shakers and contemplative cuts.   80.0          1\n",
       "\n",
       "[1188 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['grade'] = data['grade'].astype(float)  \n",
    "data['sentiment'] = data['grade'].apply(grade_to_sentiment)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmas'] = data['text'].apply(lemmatize, args=(False, True))\n",
    "data['pos'] = data['text'].apply(lemmatize, args=(True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grade</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immensely mediocre. I hope Ye doesn't make any...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[immensely, mediocre, I, hope, ye, make, album...</td>\n",
       "      <td>[(immensely, ADV), (mediocre, ADJ), (I, PRON),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very poor album with poor production and a lot...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[poor, album, poor, production, lot, throwaway...</td>\n",
       "      <td>[(poor, ADJ), (album, NOUN), (poor, ADJ), (pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's clearly unfinished. The best is yet to co...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[clearly, unfinished, good, yet, come, far, ba...</td>\n",
       "      <td>[(clearly, ADV), (unfinished, ADJ), (good, ADJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This review contains spoilers, click expand to...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[review, contain, spoiler, click, expand, view...</td>\n",
       "      <td>[(review, NOUN), (contain, VERB), (spoiler, NO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donda, Donda, DondaDonda, Donda, Donda, Donda,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[donda, donda, dondadonda, donda, donda, donda...</td>\n",
       "      <td>[(donda, PROPN), (donda, PROPN), (dondadonda, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Now I usually like the rock music. Actually no...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, usually, like, rock, music, actually, I, u...</td>\n",
       "      <td>[(I, PRON), (usually, ADV), (like, VERB), (roc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>This album was the BOMB!</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[album, bomb]</td>\n",
       "      <td>[(album, NOUN), (bomb, NOUN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Like every hip-hop album (even the great ones)...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, every, hip, hop, album, even, great, on...</td>\n",
       "      <td>[(like, ADP), (every, DET), (hip, NOUN), (hop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Most producers who approach the mic do so at t...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[producer, approach, mic, peril, dropout, west...</td>\n",
       "      <td>[(producer, NOUN), (approach, VERB), (mic, ADJ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>Delivers both ass-shakers and contemplative cuts.</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[deliver, shaker, contemplative, cut]</td>\n",
       "      <td>[(deliver, VERB), (shaker, NOUN), (contemplati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1188 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  grade  sentiment  \\\n",
       "0     Immensely mediocre. I hope Ye doesn't make any...    3.0          0   \n",
       "1     very poor album with poor production and a lot...    3.0          0   \n",
       "2     It's clearly unfinished. The best is yet to co...    7.0          1   \n",
       "3     This review contains spoilers, click expand to...    7.0          1   \n",
       "4     Donda, Donda, DondaDonda, Donda, Donda, Donda,...   10.0          1   \n",
       "...                                                 ...    ...        ...   \n",
       "1183  Now I usually like the rock music. Actually no...    9.0          1   \n",
       "1184                           This album was the BOMB!   10.0          1   \n",
       "1185  Like every hip-hop album (even the great ones)...   70.0          1   \n",
       "1186  Most producers who approach the mic do so at t...   70.0          1   \n",
       "1187  Delivers both ass-shakers and contemplative cuts.   80.0          1   \n",
       "\n",
       "                                                 lemmas  \\\n",
       "0     [immensely, mediocre, I, hope, ye, make, album...   \n",
       "1     [poor, album, poor, production, lot, throwaway...   \n",
       "2     [clearly, unfinished, good, yet, come, far, ba...   \n",
       "3     [review, contain, spoiler, click, expand, view...   \n",
       "4     [donda, donda, dondadonda, donda, donda, donda...   \n",
       "...                                                 ...   \n",
       "1183  [I, usually, like, rock, music, actually, I, u...   \n",
       "1184                                      [album, bomb]   \n",
       "1185  [like, every, hip, hop, album, even, great, on...   \n",
       "1186  [producer, approach, mic, peril, dropout, west...   \n",
       "1187              [deliver, shaker, contemplative, cut]   \n",
       "\n",
       "                                                    pos  \n",
       "0     [(immensely, ADV), (mediocre, ADJ), (I, PRON),...  \n",
       "1     [(poor, ADJ), (album, NOUN), (poor, ADJ), (pro...  \n",
       "2     [(clearly, ADV), (unfinished, ADJ), (good, ADJ...  \n",
       "3     [(review, NOUN), (contain, VERB), (spoiler, NO...  \n",
       "4     [(donda, PROPN), (donda, PROPN), (dondadonda, ...  \n",
       "...                                                 ...  \n",
       "1183  [(I, PRON), (usually, ADV), (like, VERB), (roc...  \n",
       "1184                      [(album, NOUN), (bomb, NOUN)]  \n",
       "1185  [(like, ADP), (every, DET), (hip, NOUN), (hop,...  \n",
       "1186  [(producer, NOUN), (approach, VERB), (mic, ADJ...  \n",
       "1187  [(deliver, VERB), (shaker, NOUN), (contemplati...  \n",
       "\n",
       "[1188 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_freqlist(reviews, reviews_pos): #создаем частотные списки, делаем из них множества\n",
    "    freqlist = Counter()\n",
    "    all_bigrams = []\n",
    "    for text in reviews:\n",
    "        for word in text:\n",
    "            if word.isalpha():\n",
    "                freqlist[word] += 1\n",
    "    for text in reviews_pos:\n",
    "        bigrams = get_bigrams(text)\n",
    "        all_bigrams.extend(bigrams)\n",
    "    l = [*dict(freqlist).keys()]\n",
    "    l.extend(all_bigrams)\n",
    "    freqlist_set = set(l)\n",
    "    return freqlist_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data[data['sentiment'] == 1]['lemmas'].to_list()\n",
    "positive_with_pos = data[data['sentiment'] == 1]['pos'].to_list()\n",
    "negative = data[data['sentiment'] == 0]['lemmas'].to_list()\n",
    "negative_with_pos = data[data['sentiment'] == 0]['pos'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = collect_freqlist(positive, positive_with_pos)\n",
    "neg_set = collect_freqlist(positive, negative_with_pos)\n",
    "pos_only = pos_set.difference(neg_set) #выделяем множества только позитивных и негативных слов\n",
    "neg_only = neg_set.difference(pos_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review): #простейшая функция для определения тональности отзыва\n",
    "    prep_review = lemmatize(review, False, True)\n",
    "    pos_points = 0\n",
    "    neg_points = 0\n",
    "    bigr = list(nltk.bigrams(prep_review))\n",
    "    for word in prep_review:\n",
    "        if word in pos_only:\n",
    "            pos_points += 1\n",
    "        if word in neg_only:\n",
    "            neg_points += 1\n",
    "    for el in bigr:\n",
    "        b = el[0] + ' ' + el[1]\n",
    "        if b in pos_only:\n",
    "            pos_points += 1\n",
    "        if b in neg_only:\n",
    "            neg_points += 1\n",
    "    if pos_points > neg_points:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "///в прошлой дз я зачем-то сделала бесполезный шаг с делением на test/train, но не успела его переделать его для этой домашки, поэтому пришлось оставить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950 training reviews\n",
      "238 testing reviews\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['text', 'lemmas']], data[['sentiment']], test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train), 'training reviews')\n",
    "print(len(X_test), 'testing reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.5747368421052632\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = X_train['text'].apply(predict_sentiment)\n",
    "print('train accuracy:', accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "точность предсказания понизилась :( скорее всего, я что-то сделала не так..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
