{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Собираем отзывы на альбомы Канье Уэста с помощью краулера с сайта metacritic.com (выражаю благодарность однокурсникам за наводку на этот сайт)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent(verify_ssl=False)\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(url):\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albums(url): #функция, которая определяет список альбомов исполнителя\n",
    "    albums = []\n",
    "    page = parse_page(url)\n",
    "    r = page.find_all('td', {'class' : 'title brief_metascore'})\n",
    "    for album in r:\n",
    "        l = album.find('a').attrs['href']\n",
    "        albums.append(f'https://www.metacritic.com{l}/user-reviews')\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_albums = get_albums('https://www.metacritic.com/person/kanye-west')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_reviews(url): #функция, которая парсит рецензии, на вход подается ссылка на страницу с альбомом\n",
    "    all_reviews = []\n",
    "    page = parse_page(url)\n",
    "    reviews = page.find_all('div', {'class' : 'review_content'})\n",
    "    for review in reviews:\n",
    "        dic = {}\n",
    "        dic['text'] = review.find_all('div', {'class' : 'review_body'})[0].text.strip()\n",
    "        dic['grade'] = review.find_all('div', {'class' : 'review_grade'})[0].text.strip()\n",
    "        all_reviews.append(dic)\n",
    "    return all_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "for album in k_albums:\n",
    "    reviews.extend(parse_reviews(album))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(reviews) #превращаем данные в датафрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_to_sentiment(x): #выделяем положительные и отрицательные отзывы\n",
    "    if x > 10: #некоторые оценки на сайте по 100-балльной шкале\n",
    "        sent = x / 10\n",
    "    else:\n",
    "        sent = x\n",
    "    if sent <= 5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>grade</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Immensely mediocre. I hope Ye doesn't make any...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's clearly unfinished. The best is yet to co...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This review contains spoilers, click expand to...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donda, Donda, DondaDonda, Donda, Donda, Donda,...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The album is such a dissappointment I can't ev...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Now I usually like the rock music. Actually no...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>This album was the BOMB!</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Like every hip-hop album (even the great ones)...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Most producers who approach the mic do so at t...</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Delivers both ass-shakers and contemplative cuts.</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  grade  sentiment\n",
       "0     Immensely mediocre. I hope Ye doesn't make any...    3.0          0\n",
       "1     It's clearly unfinished. The best is yet to co...    7.0          1\n",
       "2     This review contains spoilers, click expand to...    7.0          1\n",
       "3     Donda, Donda, DondaDonda, Donda, Donda, Donda,...   10.0          1\n",
       "4     The album is such a dissappointment I can't ev...    0.0          0\n",
       "...                                                 ...    ...        ...\n",
       "1181  Now I usually like the rock music. Actually no...    9.0          1\n",
       "1182                           This album was the BOMB!   10.0          1\n",
       "1183  Like every hip-hop album (even the great ones)...   70.0          1\n",
       "1184  Most producers who approach the mic do so at t...   70.0          1\n",
       "1185  Delivers both ass-shakers and contemplative cuts.   80.0          1\n",
       "\n",
       "[1186 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['grade'] = data['grade'].astype(float)  \n",
    "data['sentiment'] = data['grade'].apply(grade_to_sentiment)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1017\n",
       "0     169\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Токенизируем, лемматизируем, приводим к нижнему регистру и удаляем стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import wordpunct_tokenize\n",
    "import nltk\n",
    "stops = set(stopwords.words('english'))\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(x, returnList = True):\n",
    "    if type(x) != str:\n",
    "        return \"\"\n",
    "    text = wordpunct_tokenize(x)\n",
    "    result = []\n",
    "    for word in text:\n",
    "        if word.isalpha():\n",
    "            nf = wnl.lemmatize(word).lower()\n",
    "            if nf not in stops:\n",
    "                result.append(nf)\n",
    "    if returnList:\n",
    "        return(result)\n",
    "    else:\n",
    "        return \" \".join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemmas'] = data['text'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = data[data['sentiment'] == 1]['lemmas'].to_list()\n",
    "negative = data[data['sentiment'] == 0]['lemmas'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Создаем множества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_freqlist(reviews, max_len=300): #создаем частотные списки, делаем из них множества\n",
    "    freqlist = Counter()\n",
    "    for text in reviews:\n",
    "        for word in text:\n",
    "            if word.isalpha():\n",
    "                freqlist[word] += 1\n",
    "    l = [*dict(freqlist.most_common(max_len)).keys()]\n",
    "    freqlist_set = set(l)\n",
    "    return freqlist_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set = collect_freqlist(positive)\n",
    "neg_set = collect_freqlist(negative)\n",
    "pos_only = pos_set.difference(neg_set) #выделяем множества только позитивных и негативных слов\n",
    "neg_only = neg_set.difference(pos_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Создаем функцию для определения тональности отзыва"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(review): #простейшая функция для определения тональности отзыва\n",
    "    prep_review = lemmatize(review)\n",
    "    pos_points = 0\n",
    "    neg_points = 0\n",
    "    for word in prep_review:\n",
    "        if word in pos_only:\n",
    "            pos_points += 1\n",
    "        if word in neg_only:\n",
    "            neg_points += 1\n",
    "    if pos_points > neg_points:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948 training reviews\n",
      "238 testing reviews\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data[['text', 'lemmas']], data[['sentiment']], test_size=0.2, random_state=42)\n",
    "\n",
    "print(len(X_train), 'training reviews')\n",
    "print(len(X_test), 'testing reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.7542194092827004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_train_pred = X_train['text'].apply(predict_sentiment)\n",
    "print('train accuracy:', accuracy_score(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Способы улучшения: подобрать оптимальную частотность для \"позитивных\" и \"негативных слов\" при составлении множеств, вместо примитивной функции для определения тональности обучить ML-модель, использовать готовый словарь позитивных/негативных слов. Ну и корпус увеличить тоже не помешает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать логистическую регрессию и tf-idf:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['for_ml'] = data['text'].apply(lemmatize, returnList = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['for_ml'], data[['sentiment']], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "vect = TfidfVectorizer(ngram_range=(1,2),min_df=7)\n",
    "vect.fit(X_train)\n",
    "vect_X = vect.transform(X_train)\n",
    "clf = LogisticRegression().fit(vect_X, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy стало больше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.8613445378151261\n"
     ]
    }
   ],
   "source": [
    "y_train_regr = clf.predict(vect.transform(X_test))\n",
    "print('train accuracy:', accuracy_score(y_test, y_train_regr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
